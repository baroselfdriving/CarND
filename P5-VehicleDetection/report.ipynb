{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 5 - Vehicle Detection - Report. Vilas Chitrakaran. March 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "The objective is to develop a software pipeline to identify and track vehicles in a video stream obtained from a front-facing camera mounted on the dashboard of a car. A linear support vector machine (SVM) is trained to identify vehicles based on histogram-of-oriented-gradients (HOG) features extracted from 'car' and 'non-car' image sets. The trained SVM is then applied on the video stream to search and identify vehicles. The robustness of the identification pipeline is improved by temporal filtering techniques to discard false positives. \n",
    "\n",
    "The following video demonstrates the final result obtained from my implementation.\n",
    "\n",
    "__TODO__: Link to final video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Pipeline Development\n",
    "\n",
    "__TODO__: Give an overview of sequence of development\n",
    "\n",
    "The vehicle is instrumented with a front-facing video camera that provides an RGB video stream of the road ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction - Histogram of Oriented Gradients (HOG)\n",
    "Why use HOG and not something else?\n",
    "\n",
    "Explain how (and identify where in your code) you extracted HOG features from the training images. Explain how you settled on your final choice of HOG parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=====================================================================\n",
    "# HOG feature extraction\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Given an image, generate HOG feature vector\n",
    "# image\n",
    "# numOrientations\n",
    "# pixelsPerCell\n",
    "# cellsPerBlock\n",
    "# bVisual\n",
    "# bFeatVec\n",
    "def get_hog_features(image, numOrientations=9, pixelsPerCell=2, cellsPerBlock=8, bVisual=False, bFeatVec=True):\n",
    "    # if bVisual == True, return features, hog_image, else just return features\n",
    "    return hog(image, orientations=numOrientations, pixels_per_cell=(pixelsPerCell, pixelsPerCell),\n",
    "               cells_per_block=(cellsPerBlock, cellsPerBlock), \n",
    "               transform_sqrt=False, visualise=bVisual, feature_vector=bFeatVec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Training - Support Vector Machine\n",
    "\n",
    "Why use SVM and not something else?\n",
    "\n",
    "Describe how (and identify where in your code) you trained a classifier using your selected HOG features (and color features if you used them).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection - Sliding Window Search\n",
    "Describe how (and identify where in your code) you implemented a sliding window search. How did you decide what scales to search and how much to overlap windows?\n",
    "Show some examples of test images to demonstrate how your pipeline is working. How did you optimize the performance of your classifier?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline\n",
    "Summarise the steps in the processing pipeline. \n",
    "\n",
    "Describe how (and identify where in your code) you implemented some kind of filter for false positives and some method for combining overlapping bounding boxes.\n",
    "\n",
    "Provide a link to your final video output. Your pipeline should perform reasonably well on the entire project video (somewhat wobbly or unstable bounding boxes are ok as long as you are identifying the vehicles most of the time with minimal false positives.)\n",
    "\n",
    "Combine vehicle detection with lane detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection - Project Video\n",
    "All that remains now is to process the video sequence by applying the processing pipeline described in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3239e868b62e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minput_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"project_video.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutput_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_video\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time output_video.write_videofile(output_video_name, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'process_image' is not defined"
     ]
    }
   ],
   "source": [
    "#=====================================================================\n",
    "# process the project video\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "output_video_name = 'output.mp4'\n",
    "input_video = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "output_video = input_video.fl_image(process_image)\n",
    "%time output_video.write_videofile(output_video_name, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "Briefly discuss any problems / issues you faced in your implementation of this project. Where will your pipeline likely fail? What could you do to make it more robust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
